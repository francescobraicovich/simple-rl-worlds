import torch
import torch.nn.functional as F # For F.one_hot
import os # For os.path.exists in early stopping save/load
import matplotlib.pyplot as plt
import numpy as np
# import time # Not used in this specific function directly
import wandb # For wandb.Image

"""Handles the training loop for the JEPA state decoder model."""

def train_jepa_state_decoder(
    jepa_decoder_model, jepa_model, optimizer_jepa_decoder,
    train_dataloader, val_dataloader, loss_fn, device,
    action_dim, action_type,
    decoder_training_config, # This is jepa_decoder_training_config from the main function
    main_model_dir, # This is model_dir from the main function, for paths
    general_log_interval, # Fallback log interval
    wandb_run # New argument for wandb
):
    """
    Handles the training and validation process for the JEPA (Joint Embedding
    Predictive Architecture) State Decoder model.

    This function trains a decoder to reconstruct the next state (s_t_plus_1)
    from embeddings generated by a pre-trained JEPA model. It includes training
    and validation loops, loss computation, optimizer steps, logging with
    Weights & Biases (wandb), and an early stopping mechanism. Validation also
    includes plotting a few sample reconstructions.

    Args:
        jepa_decoder_model (torch.nn.Module): The JEPA state decoder model to be trained.
        jepa_model (torch.nn.Module): The pre-trained JEPA model, used for generating
                                      embeddings. It's set to eval mode.
        optimizer_jepa_decoder (torch.optim.Optimizer): Optimizer for the JEPA decoder.
        train_dataloader (torch.utils.data.DataLoader): DataLoader for the training set.
        val_dataloader (torch.utils.data.DataLoader, optional): DataLoader for the validation set.
        loss_fn (callable): The loss function for training (e.g., MSE).
        device (torch.device): The device (CPU or GPU) for computations.
        action_dim (int): Dimension of the action space.
        action_type (str): Type of action space ('discrete' or 'continuous').
        decoder_training_config (dict): Configuration dictionary containing parameters
                                        like 'num_epochs', 'log_interval',
                                        'early_stopping' (patience, delta),
                                        'checkpoint_path', 'enable_validation_plot',
                                        and 'validation_plot_dir'.
        main_model_dir (str): The main directory where models and plots are saved.
                              Used to construct full checkpoint and plot paths.
        general_log_interval (int): Fallback log interval if not specified in
                                    `decoder_training_config`.
        wandb_run (wandb.sdk.wandb_run.Run, optional): Active Weights & Biases run object.

    Returns:
        str or None: The path to the best saved model checkpoint if early stopping
                     occurred and a model was saved, or if training completed and
                     no validation set was provided (last model saved). Returns None
                     if no checkpoint was saved or found.
    """
    print("\nStarting JEPA State Decoder training...")

    # move model to device
    jepa_decoder_model.to(device)

    # Extract params from decoder_training_config
    num_epochs_decoder = decoder_training_config.get('num_epochs', 50)
    decoder_log_interval = decoder_training_config.get('log_interval', general_log_interval)

    early_stopping_specific_config = decoder_training_config.get('early_stopping', {})
    # Fallback to general patience/delta if not specifically in decoder_training_config.early_stopping
    # This requires access to the general patience/delta, or they should be passed in,
    # or defined within this scope if they are meant to be independent.
    # For now, let's assume patience/delta are in early_stopping_specific_config or have defaults.
    patience_decoder = early_stopping_specific_config.get('patience', 10) # Default if not in specific config
    delta_decoder = early_stopping_specific_config.get('delta', 0.001)   # Default if not in specific config

    decoder_cp_name = decoder_training_config.get('checkpoint_path', 'best_jepa_decoder.pth')
    # Construct full checkpoint path using main_model_dir
    checkpoint_path_decoder = os.path.join(main_model_dir, decoder_cp_name)

    # Plotting directory from config
    validation_plot_dir_config = decoder_training_config.get('validation_plot_dir', "validation_plots/decoder")
    validation_plot_dir_full = validation_plot_dir_config

    early_stopping_state_decoder = {
        'best_val_loss': float('inf'),
        'epochs_no_improve': 0,
        'early_stop_flag': False,
        'patience': patience_decoder,
        'delta': delta_decoder,
        'checkpoint_path': checkpoint_path_decoder # Full path
    }

    for epoch in range(num_epochs_decoder):
        if early_stopping_state_decoder['early_stop_flag']:
            print(f"JEPA State Decoder early stopping triggered before epoch {epoch+1}. Exiting decoder training loop.")
            break

        if jepa_model: jepa_model.eval() # Main JEPA model provides embeddings
        jepa_decoder_model.train()

        epoch_loss_train = 0
        num_batches_train = len(train_dataloader) if train_dataloader else 0

        if num_batches_train == 0:
            print(f"JEPA Decoder Epoch {epoch+1} has no training data. Skipping training phase.")
        else:
            for batch_idx, (s_t, a_t, _, s_t_plus_1) in enumerate(train_dataloader):
                s_t, s_t_plus_1 = s_t.to(device), s_t_plus_1.to(device)
                if action_type == 'discrete':
                    a_t_processed = F.one_hot(a_t.long().view(-1), num_classes=action_dim).float().to(device) if a_t.ndim == 1 else F.one_hot(a_t.long(), num_classes=action_dim).float().to(device)
                    if a_t_processed.shape[0] != s_t.shape[0]:
                         a_t_processed = F.one_hot(a_t.long().view(-1), num_classes=action_dim).float().to(device)
                else:
                    a_t_processed = a_t.float().to(device)

                optimizer_jepa_decoder.zero_grad()
                with torch.no_grad():
                    if not jepa_model: # Should be caught by caller, but good to check
                        print("Error: Main JEPA model is None for JEPA decoder training.")
                        early_stopping_state_decoder['early_stop_flag'] = True; break
                    pred_emb, _, _, _ = jepa_model(s_t, a_t_processed, s_t_plus_1)

                jepa_predictor_output = pred_emb.detach()
                reconstructed_s_t_plus_1 = jepa_decoder_model(jepa_predictor_output)
                loss = loss_fn(reconstructed_s_t_plus_1, s_t_plus_1)
                loss.backward()
                optimizer_jepa_decoder.step()
                epoch_loss_train += loss.item()

                if (batch_idx + 1) % decoder_log_interval == 0:
                    if wandb_run:
                        log_data_decoder_batch = {
                            "JEPA_Decoder/train/Loss": loss.item(),
                            "JEPA_Decoder/train/Learning_Rate": optimizer_jepa_decoder.param_groups[0]['lr']
                        }
                        # step current_decoder_global_step aligns with "JEPA_Decoder/train/step"
                        wandb_run.log(log_data_decoder_batch)
            if early_stopping_state_decoder['early_stop_flag']: break # From error in batch loop

        avg_train_loss = epoch_loss_train / num_batches_train if num_batches_train > 0 else 0

        if wandb_run:
            wandb_run.log({
                "JEPA_Decoder/train_epoch_avg/Loss": avg_train_loss
            }) # step epoch + 1 aligns with "JEPA_Decoder/epoch"

        # Validation Phase
        if val_dataloader:
            jepa_decoder_model.eval()
            if jepa_model: jepa_model.eval()

            epoch_loss_val = 0
            num_batches_val = len(val_dataloader)
            with torch.no_grad():
                for val_batch_idx, (s_t_val, a_t_val, _, s_t_plus_1_val) in enumerate(val_dataloader):
                    s_t_val, s_t_plus_1_val = s_t_val.to(device), s_t_plus_1_val.to(device)
                    if action_type == 'discrete':
                        a_t_val_processed = F.one_hot(a_t_val.long().view(-1), num_classes=action_dim).float().to(device) if a_t_val.ndim == 1 else F.one_hot(a_t_val.long(), num_classes=action_dim).float().to(device)
                        if a_t_val_processed.shape[0] != s_t_val.shape[0]:
                           a_t_val_processed = F.one_hot(a_t_val.long().view(-1), num_classes=action_dim).float().to(device)
                    else:
                        a_t_val_processed = a_t_val.float().to(device)

                    if not jepa_model:
                         print("Error: Main JEPA model is None during JEPA decoder validation.")
                         early_stopping_state_decoder['early_stop_flag'] = True; break
                    pred_emb_val, _, _, _ = jepa_model(s_t_val, a_t_val_processed, s_t_plus_1_val)
                    jepa_predictor_output_val = pred_emb_val.detach()
                    reconstructed_s_t_plus_1_val = jepa_decoder_model(jepa_predictor_output_val)
                    val_loss = loss_fn(reconstructed_s_t_plus_1_val, s_t_plus_1_val)
                    epoch_loss_val += val_loss.item()

                    # Plotting logic
                    if val_batch_idx == 10 and decoder_training_config.get('enable_validation_plot', True):
                        os.makedirs(validation_plot_dir_full, exist_ok=True)
                        num_plot_samples = min(4, s_t_val.shape[0])
                        random_indices = np.random.choice(s_t_val.shape[0], num_plot_samples, replace=False) if s_t_val.shape[0] > num_plot_samples else range(s_t_val.shape[0])
                        for i in random_indices:
                            curr_img_np = s_t_val[i].cpu().numpy()
                            true_img_np = s_t_plus_1_val[i].cpu().numpy()
                            pred_img_np = reconstructed_s_t_plus_1_val[i].cpu().numpy()

                            # Process all three images consistently
                            processed_images = []
                            for img_np in [curr_img_np, true_img_np, pred_img_np]:
                                if img_np.shape[0] == 1 or img_np.shape[0] == 3: # C, H, W
                                    img_np = np.transpose(img_np, (1, 2, 0))
                                if img_np.shape[-1] == 1: # Grayscale, squeeze channel
                                    img_np = img_np.squeeze(axis=2)
                                if img_np.dtype == np.float32 or img_np.dtype == np.float64: # Clip if float
                                    img_np = np.clip(img_np, 0, 1)
                                processed_images.append(img_np)

                            curr_img_processed, true_img_processed, pred_img_processed = processed_images

                            fig, axes = plt.subplots(1, 3, figsize=(12, 4))
                            axes[0].imshow(curr_img_processed); axes[0].set_title("Current State (s_t)"); axes[0].axis('off')
                            axes[1].imshow(true_img_processed); axes[1].set_title("True Next State (s_{t+1})"); axes[1].axis('off')
                            axes[2].imshow(pred_img_processed); axes[2].set_title("Predicted Next State (s'_{t+1})"); axes[2].axis('off')

                            plot_filename = os.path.join(validation_plot_dir_full, f"epoch_{epoch+1}_sample_{i}_comparison.png")
                            plt.savefig(plot_filename)
                            plt.close(fig)

                        print(f"  Saved {num_plot_samples} validation image samples to {validation_plot_dir_full}")
                if early_stopping_state_decoder['early_stop_flag']: break

                avg_val_loss = epoch_loss_val / num_batches_val if num_batches_val > 0 else float('inf')
                print(f"  Epoch {epoch+1}/{num_epochs_decoder:<5} | {'Avg Train Loss':<22}: {avg_train_loss:>8.4f} | {'Avg Val Loss':<22}: {avg_val_loss:>8.4f}")

                if wandb_run:
                    wandb_run.log({
                        "JEPA_Decoder/val/Loss": avg_val_loss
                    }) # step epoch + 1 aligns with "JEPA_Decoder/epoch"

                if avg_val_loss < early_stopping_state_decoder['best_val_loss'] - early_stopping_state_decoder['delta']:
                    early_stopping_state_decoder['best_val_loss'] = avg_val_loss
                    if early_stopping_state_decoder['checkpoint_path']:
                        os.makedirs(os.path.dirname(early_stopping_state_decoder['checkpoint_path']), exist_ok=True)
                        torch.save(jepa_decoder_model.state_dict(), early_stopping_state_decoder['checkpoint_path'])
                    early_stopping_state_decoder['epochs_no_improve'] = 0
                    print(f"  JEPA Decoder: Val loss improved. Saved model to {early_stopping_state_decoder['checkpoint_path']}")
                else:
                    early_stopping_state_decoder['epochs_no_improve'] += 1
                    print(f"  JEPA Decoder: No val improvement for {early_stopping_state_decoder['epochs_no_improve']} epochs.")
                    if early_stopping_state_decoder['epochs_no_improve'] >= early_stopping_state_decoder['patience']:
                        early_stopping_state_decoder['early_stop_flag'] = True
                        print("  JEPA Decoder: Early stopping triggered.")
        else: # No validation dataloader
            print(f" JEPA Decoder Epoch {epoch+1} Training Summary (No Validation)")
            if early_stopping_state_decoder['checkpoint_path']: # Save last epoch if no validation
                os.makedirs(os.path.dirname(early_stopping_state_decoder['checkpoint_path']), exist_ok=True)
                torch.save(jepa_decoder_model.state_dict(), early_stopping_state_decoder['checkpoint_path'])
                print(f"  JEPA Decoder: Saved model from last epoch to {early_stopping_state_decoder['checkpoint_path']} (no validation set)")

        if early_stopping_state_decoder['early_stop_flag']: break

    print("JEPA State Decoder training finished.")

    # Load the best model if it was saved
    best_checkpoint_file = early_stopping_state_decoder['checkpoint_path']
    if best_checkpoint_file and os.path.exists(best_checkpoint_file):
        print(f"Loading best JEPA State Decoder model from {best_checkpoint_file}")
        jepa_decoder_model.load_state_dict(torch.load(best_checkpoint_file, map_location=device))
        return best_checkpoint_file
    elif best_checkpoint_file: # Path was set, but no file (e.g. no training/val epochs ran or never improved)
         print(f"JEPA State Decoder checkpoint {best_checkpoint_file} not found. Using model state as is.")
         return None
    return None
